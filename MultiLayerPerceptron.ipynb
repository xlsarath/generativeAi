{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ade6e8-5628-453f-bf1f-30a12f5d1c94",
   "metadata": {},
   "source": [
    "## MultiLayerPerceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7e140cf-97b3-4a60-a42a-e97607acaa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class NumberSumDataset(Dataset):\n",
    "    def __init__(self, data_range=(1, 10)):\n",
    "        self.numbers = list(range(data_range[0], data_range[1]))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        number1 = float(self.numbers[index // len(self.numbers)])\n",
    "        number2 = float(self.numbers[index % len(self.numbers)])\n",
    "        return torch.tensor([number1, number2]), torch.tensor([number1 + number2])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.numbers) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a545ad8e-ff9b-459f-8798-279b7a7603de",
   "metadata": {},
   "source": [
    "## 2 Custom Dataset: NumberSumDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a931ae1b-bf46-496b-b458-52e6d3a878ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumberSumDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A synthetic dataset that returns every ordered pair (i, j)\n",
    "    in a specified range and labels it with their sum.\n",
    "\n",
    "    Example with range (1, 4):\n",
    "        index 0 → (1, 1) →  2\n",
    "        index 1 → (1, 2) →  3\n",
    "        index 2 → (1, 3) →  4\n",
    "        index 3 → (2, 1) →  3\n",
    "        ...\n",
    "    \"\"\"\n",
    "    def __init__(self, data_range=(1, 10)):\n",
    "        # Store all integers in the range [start, end)\n",
    "        self.numbers = list(range(*data_range))\n",
    "\n",
    "    def __len__(self):\n",
    "        # Total ordered pairs = N²\n",
    "        return len(self.numbers) ** 2\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Map the flat index to a 2-D index:\n",
    "            row = index // N\n",
    "            col = index %  N\n",
    "        \"\"\"\n",
    "        N = len(self.numbers)\n",
    "        number1 = float(self.numbers[index // N])   # row element\n",
    "        number2 = float(self.numbers[index %  N])   # column element\n",
    "        pair     = torch.tensor([number1, number2])\n",
    "        the_sum  = torch.tensor([number1 + number2])\n",
    "        return pair, the_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406bef9b-0d88-4a93-9f72-383004f74f87",
   "metadata": {},
   "source": [
    "### Quick sanity-check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5664a72d-57d1-4b4a-a68f-49725ca0db69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1., 1.]), tensor([2.]))\n",
      "(tensor([1., 2.]), tensor([3.]))\n",
      "(tensor([1., 3.]), tensor([4.]))\n",
      "(tensor([1., 4.]), tensor([5.]))\n",
      "(tensor([1., 5.]), tensor([6.]))\n"
     ]
    }
   ],
   "source": [
    "toy_set = NumberSumDataset(data_range=(1, 6))\n",
    "for i in range(5):\n",
    "    print(toy_set[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7023957e-d679-4c59-aabf-3a429d8f1802",
   "metadata": {},
   "source": [
    "## 3 Define an MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dae564df-b75d-46fa-ac31-907ff4f829e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple 2-layer feed-forward network that learns f(x, y) = x + y.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size: int = 2, hidden_size: int = 128):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(input_size, hidden_size)\n",
    "        self.out    = nn.Linear(hidden_size, 1)\n",
    "        self.act    = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.hidden(x))\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0919642-607a-4cfc-9fb9-7e55b4684768",
   "metadata": {},
   "source": [
    "## 4 Create DataLoader, Model, Loss, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81f485a9-ec86-43d2-b44f-772c32b3e1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full dataset: numbers 0‒99  →  100² = 10 000 samples\n",
    "dataset    = NumberSumDataset(data_range=(0, 100))\n",
    "dataloader = DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "model        = MLP(input_size=2)\n",
    "criterion    = nn.MSELoss()\n",
    "optimizer    = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8237bda-7bf9-434d-b973-651cc544f6d4",
   "metadata": {},
   "source": [
    "## 5 Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a47d50d-40f7-4763-abd3-654e2a2cace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 — total batch loss: 240244.33343\n",
      "Epoch  1 — total batch loss: 2406.13129\n",
      "Epoch  2 — total batch loss: 746.29922\n",
      "Epoch  3 — total batch loss: 67.56002\n",
      "Epoch  4 — total batch loss: 1.69477\n",
      "Epoch  5 — total batch loss: 1.12241\n",
      "Epoch  6 — total batch loss: 0.89274\n",
      "Epoch  7 — total batch loss: 0.66531\n",
      "Epoch  8 — total batch loss: 0.55421\n",
      "Epoch  9 — total batch loss: 0.49038\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for pairs, targets in dataloader:\n",
    "        preds = model(pairs)              # forward pass\n",
    "        loss  = criterion(preds, targets) # compute loss\n",
    "\n",
    "        loss.backward()                   # back-prop\n",
    "        optimizer.step()                  # update weights\n",
    "        optimizer.zero_grad()             # reset gradients\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch:2d} — total batch loss: {running_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0057ea16-5909-46d3-a6c7-db3ec390056a",
   "metadata": {},
   "source": [
    "## 6 Quick Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fcce9bd-4682-4c41-8c4d-bec4c5f2c211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction for 3 + 7 ≈ 10.0564\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_pair = torch.tensor([3.0, 7.0])\n",
    "    prediction = model(test_pair)\n",
    "    print(f\"Model prediction for 3 + 7 ≈ {prediction.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84a7a5e-e761-453c-a73e-af5960cd5ed8",
   "metadata": {},
   "source": [
    "# Detailed Walk-Through of a Two-Layer MLP for Addition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73c938f-a8ca-4c04-aa1a-8eca59a3e11f",
   "metadata": {},
   "source": [
    "## 1  Network Architecture and Shapes\n",
    "\n",
    "| Layer | Weight matrix shape | Bias shape | Purpose |\n",
    "|-------|--------------------|------------|---------|\n",
    "| **Hidden (L₁)** | 128 × 2 | 128 | Project 2-D input → 128 hidden neurons |\n",
    "| **ReLU** | — | — | Non-linearity (zeroes negatives) |\n",
    "| **Output (L₂)** | 1 × 128 | 1 | Reduce 128 features → single scalar |\n",
    "\n",
    "> *Only two trainable `Linear` layers ⇒ a **1-hidden-layer network**.<br>\n",
    "> In this example we’ll shrink the hidden layer to **3 neurons** so the math is easy to see.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde377bd-1345-4d11-85e4-83ed12329a26",
   "metadata": {},
   "source": [
    "## 2  Forward Pass (single sample \\([3,7]\\))\n",
    "\n",
    "Assume tiny, fixed parameters:\n",
    "W₁ = [[ 0.10, 0.20],\n",
    "[-0.40, 0.30],\n",
    "[ 0.05, -0.10]]\n",
    "b₁ = [0.01, 0.00, -0.02]\n",
    "\n",
    "W₂ = [[ 0.60, -0.20, 0.40]]\n",
    "b₂ = [0.03]\n",
    "\n",
    "\n",
    "\n",
    "### 1. Hidden Linear Transform\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{z}_1 &= W_1 \\cdot \\mathbf{x} + \\mathbf{b}_1 \\\\\n",
    "&= \\begin{bmatrix}\n",
    "0.10 \\cdot 3 + 0.20 \\cdot 7 + 0.01 \\\\\n",
    "-0.40 \\cdot 3 + 0.30 \\cdot 7 + 0.00 \\\\\n",
    "0.05 \\cdot 3 + (-0.10) \\cdot 7 - 0.02\n",
    "\\end{bmatrix} \\\\\n",
    "&= \\begin{bmatrix}\n",
    "1.81 \\\\\n",
    "0.90 \\\\\n",
    "-0.47\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### 2. ReLU Activation\n",
    "\n",
    "$$\n",
    "\\mathbf{h} = \\text{ReLU}(\\mathbf{z}_1) =\n",
    "\\begin{bmatrix}\n",
    "1.81 \\\\\n",
    "0.90 \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "### 3. Output Layer\n",
    "\n",
    "$$\n",
    "\\hat{y} = W_2 \\cdot \\mathbf{h} + b_2 = 0.6 \\cdot 1.81 + (-0.2) \\cdot 0.90 + 0.4 \\cdot 0 + 0.03 = 1.116\n",
    "$$\n",
    "\n",
    "The untrained network predicts:\n",
    "\n",
    "$$\n",
    "\\hat{y} \\approx 1.12 \\quad \\text{(instead of the correct sum } y = 10\\text{)}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a23c49-62fc-4dc1-9df8-5ecb9fcb326c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "494bd87f-b92c-48ba-9efc-f4bc1cdb366a",
   "metadata": {},
   "source": [
    "## 3. Loss and Backpropagation\n",
    "\n",
    "---\n",
    "\n",
    "### 3.1 Mean Squared Error (MSE)\n",
    "\n",
    "The **Mean Squared Error (MSE)** is the most commonly used loss function for regression problems. It computes the average of the squares of the differences between predicted and actual values.\n",
    "\n",
    "For example, suppose your model predicts:\n",
    "\n",
    "$$\n",
    "\\hat{y} = 1.116, \\quad y = 10\n",
    "$$\n",
    "\n",
    "Then the loss is:\n",
    "\n",
    "$$\n",
    "L = (\\hat{y} - y)^2 = (1.116 - 10)^2 \\approx 79.3\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 3.1.1 Understanding Loss Functions: MSE and Alternatives\n",
    "\n",
    "Loss functions quantify how well (or badly) your model is performing. They form the basis for updating weights using gradients.\n",
    "\n",
    "#### 🔹 Mean Squared Error (MSE)\n",
    "\n",
    "Used for **regression tasks**:\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{n} \\sum_{i=1}^{n} (\\hat{y}_i - y_i)^2\n",
    "$$\n",
    "\n",
    "- Sensitive to large errors\n",
    "- Squared term amplifies outliers\n",
    "- Used when precision is key\n",
    "\n",
    "#### 🔹 Mean Absolute Error (MAE)\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{n} \\sum_{i=1}^n |\\hat{y}_i - y_i|\n",
    "$$\n",
    "\n",
    "- Less sensitive to outliers\n",
    "- Does not penalize large deviations as harshly as MSE\n",
    "\n",
    "#### 🔹 Cross-Entropy Loss\n",
    "\n",
    "- Used for **classification**\n",
    "- Not suitable for regression tasks like addition\n",
    "\n",
    "#### 🔹 Huber Loss\n",
    "\n",
    "A hybrid between MSE and MAE — it uses MSE when the error is small and MAE when it's large.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.2 Gradient Flow\n",
    "\n",
    "Once the loss is computed, we use **backpropagation** to compute the gradients — these indicate how each weight and bias should change to reduce the loss.\n",
    "\n",
    "#### 1️⃣ Gradient at Output:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\hat{y}} = 2(\\hat{y} - y) = -17.77\n",
    "$$\n",
    "\n",
    "This is the derivative of the loss function with respect to the model’s prediction.\n",
    "\n",
    "#### 2️⃣ Gradient w.r.t. Output Layer (W₂ and b₂):\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_2} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\mathbf{h}^\\top\n",
    "$$\n",
    "\n",
    "- \\( \\mathbf{h} \\): hidden layer activation\n",
    "- Shape: [1 × hidden_size]\n",
    "\n",
    "#### 3️⃣ Gradient w.r.t Hidden Activations:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{h}} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot W_2^\\top\n",
    "$$\n",
    "\n",
    "This propagates error back to the hidden layer from the output layer.\n",
    "\n",
    "#### 4️⃣ ReLU Derivative (Activation Backprop):\n",
    "\n",
    "The ReLU function blocks gradients for negative inputs:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{z}_1} = \\frac{\\partial L}{\\partial \\mathbf{h}} \\cdot \\text{ReLU}'(\\mathbf{z}_1)\n",
    "$$\n",
    "\n",
    "- Only positive neurons in \\( \\mathbf{z}_1 \\) pass gradient through\n",
    "- Others get zero\n",
    "\n",
    "#### 5️⃣ Gradient w.r.t Hidden Layer Weights (W₁ and b₁):\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_1} = \\frac{\\partial L}{\\partial \\mathbf{z}_1} \\cdot \\mathbf{x}^\\top\n",
    "$$\n",
    "\n",
    "- \\( \\mathbf{x} \\): input vector\n",
    "\n",
    "---\n",
    "\n",
    "### 3.3 Parameter Update\n",
    "\n",
    "After calculating gradients, the **optimizer** updates each parameter to reduce the loss.\n",
    "\n",
    "#### Formula:\n",
    "\n",
    "$$\n",
    "\\theta \\leftarrow \\theta - \\eta \\cdot \\frac{\\partial L}{\\partial \\theta}\n",
    "$$\n",
    "\n",
    "- \\( \\theta \\): weight or bias\n",
    "- \\( \\eta \\): learning rate (controls step size)\n",
    "\n",
    "---\n",
    "\n",
    "### 3.3.1 Optimizers\n",
    "\n",
    "#### 🔹 SGD (Stochastic Gradient Descent)\n",
    "\n",
    "$$\n",
    "\\theta = \\theta - \\eta \\cdot \\frac{\\partial L}{\\partial \\theta}\n",
    "$$\n",
    "\n",
    "- Simple and effective\n",
    "- May be slow to converge\n",
    "\n",
    "#### 🔹 Adam (Adaptive Moment Estimation)\n",
    "\n",
    "- **Used in your MLP model**\n",
    "- Combines momentum + adaptive learning rates\n",
    "- Faster and more robust for most tasks\n",
    "\n",
    "**PyTorch handles this via**:\n",
    "```python\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e645e0-2d5a-4d05-8f48-03f3321406bd",
   "metadata": {},
   "source": [
    "## 4  Why “128” Hidden Neurons?\n",
    "\n",
    "* **Not** 128 layers—just **128 neurons** *in one layer*.  \n",
    "* More neurons ⇒ higher capacity to learn complex functions.  \n",
    "* Output stays scalar because the last layer has `out_features = 1`.  \n",
    "* For simple addition, even 3–10 neurons can reach zero error; 128 is comfortable over-capacity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a518b9-42dc-4e3e-b569-2135a55ef91e",
   "metadata": {},
   "source": [
    "## 5  End-to-End Summary\n",
    "\n",
    "Input (2) → Linear (2, 128) → ReLU → Linear (128, 1) → Output (1)\n",
    "\n",
    "* **Layers = sets of weights** (2 trainable layers here).  \n",
    "* **Neurons per layer = width** (128 hidden).  \n",
    "* `loss.backward()` auto-computes all gradients; `optimizer.step()` updates them.  \n",
    "* After training, the network converges to \\(\\hat y \\approx x_1 + x_2\\)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee664ebe-a85b-4996-9307-6e0bae25b6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for 3 + 7  →  0.8759999871253967\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn as nn\n",
    "\n",
    "demo_net = nn.Sequential(\n",
    "    nn.Linear(2, 3, bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(3, 1, bias=True)\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    demo_net[0].weight[:] = torch.tensor([[0.10, 0.20],\n",
    "                                          [-0.40, 0.30],\n",
    "                                          [0.05, -0.10]])\n",
    "    demo_net[0].bias[:]   = torch.tensor([0.01, 0.00, -0.02])\n",
    "    demo_net[2].weight[:] = torch.tensor([[0.60, -0.20, 0.40]])\n",
    "    demo_net[2].bias[:]   = torch.tensor([0.03])\n",
    "\n",
    "x = torch.tensor([[3., 7.]])\n",
    "print(\"Prediction for 3 + 7  → \", demo_net(x).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "721afa01-8d0c-4342-a4d1-12c191d9ed97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- quick visual: 2 → 3 → 1 ----------\n",
    "layer_sizes = [2, 3, 1]\n",
    "layer_x = [0, 1, 2]\n",
    "coords = []\n",
    "\n",
    "for lx, n in zip(layer_x, layer_sizes):\n",
    "    ys = [i - (n - 1) / 2 for i in range(n)]\n",
    "    coords.append([(lx, y) for y in ys])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.set_aspect('equal')\n",
    "ax.axis('off')\n",
    "\n",
    "# nodes\n",
    "for layer in coords:\n",
    "    for (x, y) in layer:\n",
    "        ax.add_patch(plt.Circle((x, y), 0.08, fill=False, lw=1.5))\n",
    "\n",
    "# edges\n",
    "for i in range(len(coords) - 1):\n",
    "    for (x1, y1) in coords[i]:\n",
    "        for (x2, y2) in coords[i + 1]:\n",
    "            ax.plot([x1, x2], [y1, y2], 'k-', lw=0.6)\n",
    "\n",
    "# labels\n",
    "ax.text(-0.1, 0.5, 'Input\\n(2)', ha='right', va='center', fontsize=10, transform=ax.transAxes)\n",
    "ax.text(0.45, 0.5, 'Hidden\\n(3)', ha='center', va='center', fontsize=10, transform=ax.transAxes)\n",
    "ax.text(1.05, 0.5, 'Output\\n(1)', ha='left', va='center', fontsize=10, transform=ax.transAxes)\n",
    "\n",
    "plt.title(\"MLP Architecture: 2 → 3 → 1\", pad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d87bf2e-392f-48a7-842c-4175193256a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
